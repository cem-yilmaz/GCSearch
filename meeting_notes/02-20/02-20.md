- frontend designed
- export parsers must make a separate `chatlog.csv` for *all* chats
	- each chat must also have an `info.csv`, which contains
		- Internal chat name
			- string, `chatlog.csv` must have the same name
				- i.e ("`FamilyGroupChat`" would have an info file `FamilyGroupChat.info.csv`, and a `FamilyGroupChat.chatlog.csv`)
				- This also must be unique
					- maybe ur export does this automatically, but check that each one is unique
				- Thoughts on prepending the social media name to the chat? i.e `FamilyGroupChat.info.csv` -> `wechat_FamilyGroupChat.info.csv`
					- We could also add this to the `info.csv` file 
		- Display name
		- Participants
	- All fields are likely not applicable to all platforms -> make sure your parser fills these in as `False` or `""`
- core
	- make a function that takes in one `<chatname>.chatlog.csv` -> `<chatname>.pii`
		- format of saving pii to be determined (`.txt`, `pickle`, whichever one is more efficient)
	- make a function 
		- that takes in a 
			- text query
				- e.g "`Efe's Birthday Party`"
			- PII
		- and returns
			- a list of tuples with `(docNo, tf_idf/ranking score)` for that query for that PII
			- we may want to limit this to top `n`
		- this query should support as many of the core features as possible
			- phrase search
			- proximity search
			- boolean search
			- maybe use BM25
			- there was other optional stuff in the lectures too

Hey everyone! Apologies we didn't have a proper virtual chat today, but myself and Efe met up and we've got a good idea for how the project should evolve.

We're focusing on the interface for the end user, but @Ray @Layla @Yu-Shin you're all still focusing on the core search engine. This is going to be the vast majority of what the project is marked on, hence why it's been allocated all of you. 

Just as a reminder, your tasks are:
- make a function that takes in one `<chatname>.chatlog.csv` file (and a tokeniser) and produces a `<chatname>.pii`
	- This is the positional inverted index that lets us lookup token positions etc etc
	- We take in the tokeniser as a variable, since we'll be supporting English/Chinese/Turkish
	- format of saving pii to be determined (`.txt`, `pickle`, whichever one is more efficient, test around)
	- **This has been added just while I've been typing this up! :) just need to add variable tokenising functions to it**
- make a seperate function
	- which takes in a
		- text query
				- e.g "`Efe's Birthday Party`"
		- a single PII
	-  and returns
		- a list of tuples with `(docNo, tf_idf/ranking score)` for that query for that PII
			- we may want to limit this to top `n`
		- this query should support as many of the core features as possible
			- phrase search
			- proximity search
			- boolean search
			- maybe use BM25
			- there was other optional stuff in the lectures too - look over these, this is where we can grab exceptionality marks quite easily!

We'll also arrange an (in person) meeting next week but if there's any problems with this just let us know. Also, me and Efe may be asking about the above functions or requesting changes if they're not working too well with our interface.

Let's keep up the phenomenal pace and quality of work!